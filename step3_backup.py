#!/usr/bin/env python3
"""
POC: HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒã‚’æŠ½å‡ºã—ã€1HTML=1ãƒšãƒ¼ã‚¸ã®PDFã‚’ç”Ÿæˆ
- ãƒšãƒ¼ã‚¸ã‚µã‚¤ã‚º: A1
- ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸Šã‹ã‚‰æµã—è¾¼ã¿
- ç”»åƒã¯ä¸Šã‹ã‚‰é †ç•ªã«ç¸¦ç©ã¿ï¼ˆé‡ãªã‚Šãªã—ï¼‰
"""
import argparse
import base64
import io
import re
from pathlib import Path
from typing import List, Tuple

from bs4 import BeautifulSoup
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import A1
from reportlab.lib.units import mm
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.cidfonts import UnicodeCIDFont
from reportlab.lib.utils import ImageReader
from PIL import Image


def extract_text_and_images(html_path: Path) -> Tuple[str, List[Tuple[str, bytes]]]:
    """
    HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã¨ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    Returns:
        text: æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ
        images: [(name, image_bytes)]
    """
    html = html_path.read_text(encoding="utf-8", errors="ignore")
    soup = BeautifulSoup(html, "html.parser")

    # script/styleã¯é™¤å»
    for tag in soup(["script", "style", "noscript"]):
        tag.decompose()

    # ç”»åƒæŠ½å‡º
    images = []
    for idx, img in enumerate(soup.find_all("img"), 1):
        src = img.get("src")
        if not src:
            continue
        if src.startswith("data:"):
            # data URI
            match = re.match(r"data:(.*?);base64,(.*)", src, re.DOTALL)
            if not match:
                continue
            b64 = match.group(2)
            try:
                image_bytes = base64.b64decode(b64)
                images.append((f"data_{idx}", image_bytes))
            except Exception:
                continue
        else:
            # ç›¸å¯¾ãƒ‘ã‚¹ã®ç”»åƒ
            img_path = (html_path.parent / src).resolve()
            if img_path.exists():
                try:
                    images.append((img_path.name, img_path.read_bytes()))
                except Exception:
                    continue

    # ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡º
    text = soup.get_text("\n")
    # é€£ç¶šç©ºç™½ã®æ•´ç†
    text = re.sub(r"\n{3,}", "\n\n", text)
    text = re.sub(r"[ \t]+", " ", text)
    text = text.strip()

    return text, images


def draw_wrapped_text(c, text: str, x: float, y: float, max_width: float, leading: float) -> float:
    """ç°¡æ˜“çš„ãªæŠ˜ã‚Šè¿”ã—ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»ã—ã€æç”»å¾Œã®yåº§æ¨™ã‚’è¿”ã™"""
    lines = []
    for raw_line in text.split("\n"):
        if not raw_line:
            lines.append("")
            continue
        line = ""
        for ch in raw_line:
            test = line + ch
            if pdfmetrics.stringWidth(test, "HeiseiMin-W3", 10) <= max_width:
                line = test
            else:
                lines.append(line)
                line = ch
        lines.append(line)

    for line in lines:
        if y < 20 * mm:
            break
        c.drawString(x, y, line)
        y -= leading
    return y


def draw_images_stacked(c, images: List[Tuple[str, bytes]], x: float, y: float, max_width: float) -> float:
    """ç”»åƒã‚’ä¸Šã‹ã‚‰é †ã«ç¸¦ç©ã¿ã§æç”»"""
    for name, data in images:
        if y < 30 * mm:
            break
        try:
            img = Image.open(io.BytesIO(data))
            w, h = img.size
            scale = min(1.0, max_width / w)
            draw_w = w * scale
            draw_h = h * scale
            
            if y - draw_h < 20 * mm:
                break

            c.drawImage(ImageReader(img), x, y - draw_h, width=draw_w, height=draw_h, preserveAspectRatio=True, mask='auto')
            y -= (draw_h + 8)
        except Exception:
            continue
    return y


def generate_pdf(input_dir: Path, output_path: Path, pages_per_file: int = None):
    html_files = sorted([f for f in input_dir.glob("*.html") if "index.html" not in f.name and "temp" not in f.name])
    if not html_files:
        print(f"HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}")
        return

    pdfmetrics.registerFont(UnicodeCIDFont("HeiseiMin-W3"))
    
    print("=" * 60)
    if pages_per_file:
        print(f"ğŸ“„ HTML â†’ PDFå¤‰æ›ï¼ˆ{pages_per_file}ãƒšãƒ¼ã‚¸ã”ã¨ã«åˆ†å‰²ï¼‰")
    else:
        print(f"ğŸ“„ HTML â†’ PDFå¤‰æ›")
    print("=" * 60)
    print(f"å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(html_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    print()
    
    width, height = A1
    margin_x = 25 * mm
    margin_y = 25 * mm
    max_width = width - 2 * margin_x
    leading = 16
    
    output_files = []
    
    if pages_per_file is None:
        # åˆ†å‰²ãªã—ï¼š1ã¤ã®PDFã«å…¨ã¦
        c = canvas.Canvas(str(output_path), pagesize=A1)
        for i, html_path in enumerate(html_files, 1):
            text, images = extract_text_and_images(html_path)
            c.setFont("HeiseiMin-W3", 10)

            y = height - margin_y
            if text:
                y = draw_wrapped_text(c, text, margin_x, y, max_width, leading)
                y -= 10
            if images:
                y = draw_images_stacked(c, images, margin_x, y, max_width)

            c.showPage()
            print(f"[{i}/{len(html_files)}] OK: {html_path.name}")

        c.save()
        print(f"\nâœ… PDFä½œæˆå®Œäº†: {output_path}")
        output_files.append(output_path)
    else:
        # åˆ†å‰²ã‚ã‚Šï¼špages_per_fileã”ã¨ã«PDFã‚’åˆ†å‰²
        base_name = output_path.stem
        output_dir = output_path.parent
        file_count = 0
        c = None
        page_count = 0
        
        for i, html_path in enumerate(html_files, 1):
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
            if c is None:
                file_count += 1
                pdf_path = output_dir / f"{base_name}-{file_count:03d}.pdf"
                c = canvas.Canvas(str(pdf_path), pagesize=A1)
                page_count = 0
                print(f"\nğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ« {file_count}: {pdf_path.name}")
            
            text, images = extract_text_and_images(html_path)
            c.setFont("HeiseiMin-W3", 10)

            y = height - margin_y
            if text:
                y = draw_wrapped_text(c, text, margin_x, y, max_width, leading)
                y -= 10
            if images:
                y = draw_images_stacked(c, images, margin_x, y, max_width)

            c.showPage()
            page_count += 1
            print(f"  [{i}/{len(html_files)}] ãƒšãƒ¼ã‚¸ {page_count}: {html_path.name}")
            
            # pages_per_fileã«é”ã—ãŸã‚‰ä¿å­˜ã—ã¦æ¬¡ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¸
            if page_count >= pages_per_file:
                c.save()
                print(f"  âœ… ä¿å­˜: {pdf_path.name} ({page_count}ãƒšãƒ¼ã‚¸)")
                output_files.append(pdf_path)
                c = None
        
        # æ®‹ã‚Šã®ãƒšãƒ¼ã‚¸ã‚’ä¿å­˜
        if c is not None:
            c.save()
            print(f"  âœ… ä¿å­˜: {pdf_path.name} ({page_count}ãƒšãƒ¼ã‚¸)")
            output_files.append(pdf_path)
        
        print("\n" + "=" * 60)
        print(f"âœ… PDFä½œæˆå®Œäº†: {file_count}ãƒ•ã‚¡ã‚¤ãƒ«")
        for f in output_files:
            print(f"ğŸ“ {f.name}")
        print("=" * 60)


def main():
    parser = argparse.ArgumentParser(description="HTMLã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆ/ç”»åƒã‚’æŠ½å‡ºã—ã¦PDFã‚’ç”Ÿæˆ")
    parser.add_argument("input_dir", help="HTMLãƒ•ã‚©ãƒ«ãƒ€ (ä¾‹: capture/tik-tok/html)")
    parser.add_argument("--output", default=None, help="å‡ºåŠ›PDF (çœç•¥æ™‚: input_dir/../output.pdf)")
    parser.add_argument("--pages-per-file", type=int, default=None, help="ãƒšãƒ¼ã‚¸åˆ†å‰²æ•°ï¼ˆä¾‹: 50ï¼‰")
    args = parser.parse_args()

    input_dir = Path(args.input_dir)
    if not input_dir.exists():
        print(f"å…¥åŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_dir}")
        return

    if args.output:
        output_path = Path(args.output)
    else:
        output_path = input_dir.parent / "output.pdf"

    generate_pdf(input_dir, output_path, args.pages_per_file)


if __name__ == "__main__":
    main()
